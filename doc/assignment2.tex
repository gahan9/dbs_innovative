%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Article
% Database System
% Assignment 2: Impact of queries
%
% Gahan M. Saraiya
% 18MCEC10
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------------------------------
%       PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[paper=letter, fontsize=12pt]{article}
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{lipsum} % Package to generate dummy text throughout this template
\usepackage{blindtext}
\usepackage{graphicx} 
\usepackage{caption}
\usepackage{subcaption}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{bbding}  % to use custom itemize font
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics
\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
%\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])
\usepackage{hyperref} % For hyperlinks in the PDF
\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them
\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text
\usepackage{titlesec} % Allows customization of titles

\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections

\date{}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=cyan,
	pdfauthor={Gahan Saraiya},
	pdfcreator={Gahan Saraiya},
	pdfproducer={Gahan Saraiya},
}

\usepackage{makecell}
\usepackage{longtable}

\newcommand*\tick{\item[\Checkmark]}
\newcommand*\good{\CheckmarkBold}
\newcommand*\arrow{\item[$\Rightarrow$]}
\newcommand*\fail{\item[\XSolidBrush]}
\newcommand*\bad{\XSolidBrush}
\usepackage{minted} % for highlighting code sytax
\usepackage{xcolor} % for highlighting code sytax
\definecolor{LightGray}{gray}{0.9}

\setminted[text]{
	frame=lines, 
	breaklines,
	baselinestretch=1.2,
	bgcolor=LightGray,
	%	fontsize=\small
}
\setminted[sql]{
	frame=lines, 
	breaklines,
	baselinestretch=1.2,
	bgcolor=LightGray,
	%	fontsize=\small
}

\setminted[python]{
	frame=lines, 
	breaklines, 
	linenos,
	baselinestretch=1.2,
	%	bgcolor=LightGray,
	%	fontsize=\small
}
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height
\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer

\fancyhead[C]{Institute of Technology, Nirma University $\bullet$ November 2018} % Custom header text

\fancyfoot[RO,LE]{\thepage} % Custom footer text
%----------------------------------------------------------------------------------------
%       TITLE SECTION
%----------------------------------------------------------------------------------------
\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont\textbf{Innovative Assignment 2}} % Article title
\author{
\large
{\textsc{Gahan Saraiya (18MCEC10), Rushi Trivedi (18MCEC08), Raj Kothari (18MCEC07)}}\\[2mm]
%\thanks{A thank you or further information}\\ % Your name
\normalsize \href{mailto:18mcec10@nirmauni.ac.in}{18mcec10@nirmauni.ac.in}, % Your email address
\normalsize \href{mailto:18mcec10@nirmauni.ac.in}{18mcec08@nirmauni.ac.in}, % Your email address
\normalsize \href{mailto:18mcec10@nirmauni.ac.in}{18mcec07@nirmauni.ac.in}\\[2mm] % Your email address
}
%----------------------------------------------------------------------------------------
\begin{document}
\maketitle % Insert title
\thispagestyle{fancy} % All pages have headers and footers

\section{Introduction}\label{sec:introduction}
Aim of this assignment is to analyze impact of various indexes on any modern database (SQL or NoSQL).

Steps to be followed:
\begin{itemize}
	\item Select Database
	\item Analyze performance and cost impact of indexes for various type of query
\end{itemize}

\subsection{Hash Table inside PostgreSQL}
Postgres\footnote{referred as acronym to PostgreSQL} scans over all the records in one of the tables from the join and saves them in a hash table.

\section{Implementation}
\label{sec:implementation}
\subsection{Considerations}

%\begin{table}[H]
%	\setlength{\parindent}{-5em} 
	\renewcommand{\arraystretch}{2} % Default value: 1
	\begin{longtable}{c | c | p{9cm} }
		Variable & Value & Detail
		\\ \hline
		Database & PostgreSQL & 
		\\ \hline
		Analyze scale factor & $0.1$ & Number of tuple inserts, updates, or deletes prior to analyze as a fraction of reltuples.
		\\ \hline
		Analyze Threshold & $50$ & Minimum number of tuple inserts, updates, or deletes prior to analyze.
		\\ \hline
		Block Size & $8192$ & Shows the size of a disk block.
		\\ \hline
		CPU Index Tuple cost & $0.005$ & Sets the planner's estimate of the cost of processing each index entry during an index scan.
		\\ \hline
		CPU operator cost & $0.0025$ & Sets the planner's estimate of the cost of processing each operator or function call.
		\\ \hline
		CPU tuple cost & $0.01$ & Sets the planner's estimate of the cost of processing each tuple (row).
		\\ \hline
		cursor tuple fraction & $0.1$ & Sets the planner's estimate of the fraction of a cursor's rows that will be retrieved.
		\\ \hline
		deadlock timeout & $1s$ & Sets the time to wait on a lock before checking for deadlock.
		\\ \hline
		commit delay & $0\mu s$ & Sets the delay in microseconds between transaction commit and flushing WAL\footnote{WAL - Write Ahead Logging} to disk.
		\\ \hline
		commit sibling & $5\mu s$ & Sets the minimum concurrent open transactions before performing commit\_delay.
		\\ \hline
		Effective cache size & $4GB$ & Sets the planner's assumption about the size of the disk cache.
		\\ \hline
		Effective IO concurrency & $1$ & Number of simultaneous requests that can be handled efficiently by the disk subsystem.
		\\ \hline
		Log Rotation Age & $1d$ & Automatic log file rotation will occur after N minutes.
		\\ \hline
		Log Rotation Size & $10MB$ & Automatic log file rotation will occur after N kilobytes.
		\\ \hline
		Maintenance Work Memory & $64MB$ & Sets the maximum memory to be used for maintenance operations.
		\\ \hline
		Max Connections & $100$ & Sets the maximum number of concurrent connections.
		\\ \hline
		Max files per process & $1000$ & Sets the maximum number of simultaneously open files for each server process.
		\\ \hline
		Max function arguments & $100$ & Shows the maximum number of function arguments.
		\\ \hline
		Max Index Keys & $32$ & Shows the maximum number of index keys.
		\\ \hline
		Max Stack depth & $2MB$ & Sets the maximum stack depth, in kilobytes.
		\\ \hline
		Max WAL Size & $1GB$ & Sets the WAL size that triggers a checkpoint.
		\\ \hline
		Min WAL Size & $80MB$ & Sets the minimum size to shrink the WAL to.
		\\ \hline
		Segment Size & $1GB$ & Shows the number of pages per disk file.
		\\ \hline
		Work Memory & $4MB$ & Sets the maximum memory to be used for query workspaces.
		\\ \hline
		
		\caption{Consideration and variables}
	\end{longtable}
%\end{table}
\subsection{Schema}
\inputminted{sql}{schema_structure.sql}

\subsection{Status}
\paragraph{Total Entries} 2096169

\section{Query Impact}

\subsection{Exact Match/ Point Query}
\begin{minted}{sql}
EXPLAIN ANALYZE select * from collection_title where title like '%Batman%' and title_id='tt0060153' and region='US';
\end{minted}

\begin{longtable}{p{4cm} | p{12cm}}
	\caption{Query Plan}
	\\
	Index Scan using collection\_title\_pkey on collection\_title & (cost=0.43..8.45 rows=1 width=107) (actual time=0.035..0.036 rows=1 loops=1)
	\\ \hline
	Index Cond & $(id = 334596)$
	\\ \hline
	Planning time & 0.127ms
	\\ \hline
	Execution time & 0.078ms
\end{longtable}

\subsection{Partial Match}
\begin{minted}{sql}
explain analyze select * from collection_title where ordering=1;
\end{minted}

\begin{longtable}{p{4cm} | p{12cm}}
	\caption{Query Plan}
	\\
	Seq Scan on collection\_title & (cost=0.00..48832.51 rows=859800 width=107) (actual time=0.020..305.430 rows=910215 loops=1)
	\\ \hline
	Filter & $(ordering = 1)$
	\\ \hline
	Rows Removed by Filter & 1185954
	\\ \hline
	Total Rows & 2096169
	\\ \hline
	Planning time & 0.091ms
	\\ \hline
	Execution time & 334.993ms
\end{longtable}

\begin{minted}{sql}
explain analyze select id,title_id, title from collection_title where title like '%avenger%';
\end{minted}

\begin{longtable}{p{4cm} | p{12cm}}
	\caption{Query Plan}
	\\
	Seq Scan on collection\_title & (cost=0.00..48832.51 rows=207 width=34) (actual time=0.621..490.246 rows=41 loops=1)
	\\ \hline
	Filter & $((title)::text ~~ '\%avenger\%'::text)$
	\\ \hline
	Rows Removed by Filter & 1185954
	\\ \hline
	Total Rows & 2096128
	\\ \hline
	Planning time & 0.120 ms
	\\ \hline
	Execution time & 490.282 ms
\end{longtable}

\subsection{Range Query}
\begin{minted}{sql}
explain analyze select * from collection_title where id>3566 and id <25996;
\end{minted}

\begin{longtable}{p{4cm} | p{12cm}}
	\caption{Query Plan}
	\\
	Seq Scan on collection\_title & (cost=0.00..48832.51 rows=859800 width=107) (actual time=0.020..305.430 rows=910215 loops=1)
	\\ \hline
	Filter & $(ordering = 1)$
	\\ \hline
	Rows Removed by Filter & 1185954
	\\ \hline
	Total Rows & 2096169
	\\ \hline
	Planning time & 0.091ms
	\\ \hline
	Execution time & 334.993ms
\end{longtable}


\begin{minted}{sql}
explain analyze select * from collection_title where id>3566 and id <25996;
\end{minted}

\begin{longtable}{p{4cm} | p{12cm}}
	\caption{Query Plan}
	\\
	Index Scan using collection\_title\_pkey on collection\_title & (cost=0.43..1089.81 rows=25864 width=107) (actual time=0.168..44.540 rows=22429 loops=1)
	\\ \hline
	Index Cond & $((id > 3566) AND (id < 25996))$
	\\ \hline
	Planning time & 0.0140 ms
	\\ \hline
	Execution time & 45.695 ms
\end{longtable}

\section{execution plan nodes}
\subsection{Nodes: stream-like}
	Some nodes are more or less stream-like. They don’t accumulate data from underlying nodes and produce nodes one by one, so they have no chance to allocate too much memory.
	\subsection{Nodes: stream-like}
	Some nodes are more or less stream-like. They don’t accumulate data from underlying nodes and produce nodes one by one, so they have no chance to allocate too much memory.
	\subsubsection{Examples of such nodes include}
	\begin{itemize}
		\item Sequential scan, Index Scan
		\item Nested Loop and Merge Join
		\item Append and Merge Append
		\item Unique (of a sorted input)
	\end{itemize}
	Even a single row can be quite large.
	Maximal size for individual postgres value is around 1GB, so this query requires 5GB:
	\begin{minted}{sql}
WITH cte_1g as (select repeat('a', 1024*1024*1024 - 100) as a1g)
SELECT *
FROM cte_1g a, cte_1g b, cte_1g c, cte_1g d, cte_1g e;
	\end{minted}

\subsection{Nodes: controlled}
Some of the other nodes actively use RAM but control the amount used.
They have a fall-back behavior to switch to if they realize they cannot fit $work\_mem$.
	\begin{itemize}
		\item Sort node switches from quicksort to sort-on-disk
		\item CTE and materialize nodes use temporary files if needed
		\item Group Aggregation with DISTINCT keyword can use temporary files
		\item Exact Bitmap Scan falls back to Lossy Bitmap Scan
		\item Hash Join switches to batchwise processing if it encounters more data than expected
	\end{itemize}


\subsection{Nodes: unsafe}
They are Hash Agg, hashed SubPlan and (rarely) Hash Join can use unlimited amount of RAM.
Optimizer normally avoids them when it estimates them to process huge sets, but it can easily be wrong.
	\begin{itemize}
		\item Sort node switches from quicksort to sort-on-disk
		\item CTE and materialize nodes use temporary files if needed
		\item Group Aggregation with DISTINCT keyword can use temporary files
		\item Exact Bitmap Scan falls back to Lossy Bitmap Scan
		\item Hash Join switches to batchwise processing if it encounters more data than expected
	\end{itemize}
	make the estimates wrong...
	\begin{minted}{sql}
CREATE TABLE t (a int, b int);
INSERT INTO t SELECT 0, b from generate_series(1, (10^7)::int) b;
ANALYZE t;
INSERT INTO t SELECT 1, b from generate_series(1, (5*10^5)::int) b;
	\end{minted}
	After this, autovacuum won’t update stats, as it treats the second
	insert as small w r. t. the number of rows already present.
	\begin{minted}{sql}
postgres=# EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1;
QUERY PLAN
-----------------------------------------------------------------------------------
Seq Scan on t (cost=0.00..177712.39 rows=1 width=8) (rows=500000 loops=1)
Filter: (a = 1)
Rows Removed by Filter: 10000000
Planning time: 0.059 ms
Execution time: 769.508 ms
	\end{minted}
	
	Then we run the following query
	\begin{minted}{sql}
postgres=# EXPLAIN (ANALYZE, TIMING OFF)
postgres-# SELECT * FROM t WHERE b NOT IN (SELECT b FROM t WHERE a = 1);
QUERY PLAN
---------------------------------------------------------------------------------------------
Seq Scan on t (cost=177712.39..355424.78 rows=5250056 width=8) (actual rows=9500000 loops=1)
Filter: (NOT (hashed SubPlan 1))
Rows Removed by Filter: 1000000
SubPlan 1
-> Seq Scan on t t_1 (cost=0.00..177712.39 rows=1 width=4) (actual rows=500000 loops=1)
Filter: (a = 1)
Rows Removed by Filter: 10000000
Planning time: 0.126 ms
Execution time: 3239.730 ms
and get a half-million set hashed.
	\end{minted}
	The backend used 60MB of RAM while $ work\_mem $ was only 4MB.

For a partitioned table it hashes the same condition separately for
each partition!
\begin{minted}{sql}
postgres=# EXPLAIN SELECT * FROM t WHERE b NOT IN (SELECT b FROM t1 WHERE a = 1);
QUERY PLAN
--------------------------------------------------------------------------
Append (cost=135449.03..1354758.02 rows=3567432 width=8)
-> Seq Scan on t (cost=135449.03..135449.03 rows=1 width=8)
Filter: (NOT (hashed SubPlan 1))
SubPlan 1
-> Seq Scan on t1 t1_1 (cost=0.00..135449.03 rows=1 width=4)
Filter: (a = 1)
-> Seq Scan on t2 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t3 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t4 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t5 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t6 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t7 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t8 (cost=135449.03..135487.28 rows=1130 width=8)
Filter: (NOT (hashed SubPlan 1))
-> Seq Scan on t1 (cost=135449.03..270898.05 rows=3559521 width=8)
Filter: (NOT (hashed SubPlan 1))
\end{minted}
\subsection{Unsafe nodes: Hash Join}
Hash Joins can use more memory than expected if there are many collisions on the hashed side:
\begin{minted}{sql}
postgres=# explain (analyze, costs off)
postgres-# select * from t t1 join t t2 on t1.b = t2.b where t1.a = 1;
QUERY PLAN
--------------------------------------------------------------------------------------------
Hash Join (actual time=873.321..4223.080 rows=1000000 loops=1)
Hash Cond: (t2.b = t1.b)
-> Seq Scan on t t2 (actual time=0.048..755.195 rows=10500000 loops=1)
-> Hash (actual time=873.163..873.163 rows=500000 loops=1)
Buckets: 131072 (originally 1024) Batches: 8 (originally 1) Memory Usage: 3465kB
-> Seq Scan on t t1 (actual time=748.700..803.665 rows=500000 loops=1)
Filter: (a = 1)
Rows Removed by Filter: 10000000
postgres=# explain (analyze, costs off)
postgres-# select * from t t1 join t t2 on t1.b % 1 = t2.b where t1.a = 1;
QUERY PLAN
---------------------------------------------------------------------------------------------
Hash Join (actual time=3542.413..3542.413 rows=0 loops=1)
Hash Cond: (t2.b = (t1.b % 1))
-> Seq Scan on t t2 (actual time=0.053..732.095 rows=10500000 loops=1)
-> Hash (actual time=888.131..888.131 rows=500000 loops=1)
Buckets: 131072 (originally 1024) Batches: 2 (originally 1) Memory Usage: 19532kB
-> Seq Scan on t t1 (actual time=753.244..812.959 rows=500000 loops=1)
Filter: (a = 1)
Rows Removed by Filter: 10000000
\end{minted}
\section{Measuring RAM usage...}
We have to look into /proc filesystem, namely /proc/pid/smaps
/proc/7194/smaps comprises a few sections like below which is a private memory segment . . .
\begin{minted}{sql}
....
0135f000-0a0bf000 rw-p 00000000 00:00 0
[heap]
Size: 144768 kB
Rss: 136180 kB
Pss: 136180 kB
Shared_Clean: 0 kB
Shared_Dirty: 0 kB
Private_Clean: 0 kB
Private_Dirty: 136180 kB
Referenced: 114936 kB
Anonymous: 136180 kB
AnonHugePages: 2048 kB
Swap: 0 kB
KernelPageSize: 4 kB
MMUPageSize: 4 kB
Locked: 0 kB
VmFlags: rd wr mr mw me ac sd
....
\end{minted}
or like shared buffers as below:
\begin{minted}{sql}
....
7f8ce656a000-7f8cef300000 rw-s 00000000 00:04 7334558
/dev/zero (deleted)
Size: 144984 kB
Rss: 75068 kB
Pss: 38025 kB
Shared_Clean: 0 kB
Shared_Dirty: 73632 kB
Private_Clean: 0 kB
Private_Dirty: 1436 kB
Referenced: 75068 kB
Anonymous: 0 kB
AnonHugePages: 0 kB
Swap: 0 kB
KernelPageSize: 4 kB
MMUPageSize: 4 kB
Locked: 0 kB
VmFlags: rd wr sh mr mw me ms sd
....
\end{minted}
\begin{table}
	\centering
	\begin{tabular}{c | p{2cm} | p{10cm}}
		Acronym & Full form & Description
		\\ \hline
		PSS & proportional set size & 
		\begin{itemize}
			\item For each private allocated memory chunk we count its size as is
			\item We divide the size of a shared memory chunk by the number of processes that use it
			\item $\sum_{pid}PSS(pid) =$ total memory used
			\item We can get the size of private memory of a process this way:
		\end{itemize}
		\\ \hline
		Private & & we need to count only private memory used by a backend or a worker, as all the shared is allocated by postmaster on startup.
			\begin{minted}[fontsize=\footnotesize]{sh}
$ grep '^Private' /proc/7194/smaps|awk '{a+=$2}END{print a*1024}'
7852032
			\end{minted}
		Private from psql
			\begin{minted}[breaklines=no, bgcolor=white]{sh}
do $do$ declare
l_command text :=
$p$ cat /proc/$p$ || pg_backend_pid() || $p$/smaps $p$ ||
$p$ | grep '^Private' $p$ ||
$p$ | awk '{a+=$2}END{print a * 1024}' $p$;
begin
create temp table if not exists z (a int);
execute 'copy z from program ' || quote_literal(l_command);
raise notice '%', (select pg_size_pretty(sum(a)) from z);
truncate z;
end;
$do$;
			\end{minted}
	\end{tabular}
\end{table}
%----------------------------------------------------------------------------------------
%\end{multicols}
\end{document}
